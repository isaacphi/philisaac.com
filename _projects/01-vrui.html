---
title: "VR User Interface"
thumbnail: "/images/thumbnails/vrui.png"
header_picture: "/images/header_pics/vrui.png"
layout: project
---

	<div class="text">
		Bret Victor wrote a fascinating <a href="http://worrydream.com/ABriefRantOnTheFutureOfInteractionDesign/">blog post</a> about the future of user interfaces. He argues that most of the user interfaces between us and technology are incredibly limited because they are designed for two dimensional screens - what he calls “pictures under glass”. Our bodies are capable of so much more than simply moving your thumb or fingers a few inches, and increasingly, technology is becoming capable of much more immersive experiences. Victor is saying that user interfaces of the future will be more immersive and intuitive by taking advantage of more of the human body and better emulating interactions that come naturally. I couldn’t agree more.
	</div>

	<div class="text">
		To me, virtual reality is the most exciting recent breakthrough to change the way we think about interactions between human and computer. If you’ve ever tried it, you’ll know what I’m talking about. But that immersion remains a one-way experience. VR is really good at providing you with really stunning and intuitive images, but not yet good at letting you give inputs to the computer in a natural way. You are stuck with the the traditional “pictures behind glass” tools like mice, keyboards, and game controllers.
	</div>

	<img src="/images/project_pics/meta.jpg" class="full-width-pic" />

	<div class="caption">
		A user interacting with the Meta augmented reality headset. She has no real tactile feedback about the virtual vase she is holding.
	</div>

	<div class="text">
		Oculus and HTC both have controllers which track hand position in virtual space, but these are still just simple extensions of traditional game controllers and can’t provide a realistic simulation of the virtual environment. Some researchers have also begun working on interesting new tactile user interfaces. <a href="http://tangible.media.mit.edu/">The Tangible Media Group</a> at MIT is leading the way and publishing some fascinating research. Here’s a gem among it:
	</div>

	<iframe width="560" height="315" class="iframe-vid" src="https://www.youtube.com/embed/ouP9xNujkNo" frameborder="0" allowfullscreen></iframe>

	<div class="caption">
		The InForm by the Tangible Media Group
	</div>

	<div class="text">
		How does it work?
	</div>

	<div class="text">
		This project started out in collaboration with <a href="http://nathanchau.com/">Nathan Chau</a> as my undergraduate thesis but we hope to take it much further. It is a new user interface for VR that we call Freehand.
	</div>

	<img src="/images/project_pics/freehand_concept.png" class="half-width-pic" />
	<div class="caption">
		Illustration demonstrating the concept of Freehand. The user is convinced that they are touching the virtual red cube while in reality they are only touching the robotic arm.
	</div>

	<img src="/images/project_pics/freehand_robot.jpg" class="half-width-pic" />

	<div class="caption">
		Finished prototype.
	</div>

	<div class="text">
		It works by tracking the location of your hands and actuating a robotic arm to intersect your hands at the real-world location where virtual objects would be. It is able to simulate the weight and inertia objects, convincing you, for example, that you are holding a virtual cube that isn’t there.
	</div>

	<div class="text">
		This technology could be extended to allow for rich, intuitive, and efficient interactions with computers and virtual spaces. We are not sure exactly what the future of UI in VR will look like, but we are convinced that bringing senses beyond just sight and sound into the experience will go a long way.
	</div>

	<div class="text">
		Show me some videos!
	</div>

	<iframe width="420" height="315" class="iframe-vid" src="https://www.youtube.com/embed/fZe9T4OPr2E" frameborder="0" allowfullscreen></iframe>

	<div class="caption">
		Video of me interacting with a virtual cube.
	</div>

	<iframe width="560" height="315" class="iframe-vid" src="https://www.youtube.com/embed/RqK64vmy1HI" frameborder="0" allowfullscreen></iframe>

	<div class="caption">
		This video is synced to the previous one. This is my point of view.
	</div>

	<iframe width="560" height="315" class="iframe-vid" src="https://www.youtube.com/embed/yItyPwO2AAg" frameborder="0" allowfullscreen></iframe>

	<div class="caption">
		Point of view again. This time, the interface is in AR instead of VR.
	</div>

	<iframe width="560" height="315" class="iframe-vid" src="https://www.youtube.com/embed/Hye3OZda-fc" frameborder="0" allowfullscreen></iframe>
	<div class="caption">
		Simulation of interaction with more complex shapes.
	</div>
